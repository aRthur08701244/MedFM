{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_ann_file(target, shot):\n",
    "\n",
    "    dict_ann = {}\n",
    "\n",
    "    for split in [\"train\", \"val\"]:\n",
    "            \n",
    "        df_label = pd.read_csv(f\"./MedFMC/{target}/{target}_{split}.csv\")\n",
    "        if target == \"chest\":\n",
    "            df_label.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        elif target == \"colon\":\n",
    "            df_label.drop(columns=['slide_id'], inplace=True)\n",
    "        elif target == \"endo\":\n",
    "            df_label.drop(columns=['Unnamed: 0', 'study_id'], inplace=True)\n",
    "        df_label.set_index('img_id', inplace=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        # display(df_label)\n",
    "        \n",
    "        with open(f\"data_backup/{target}_{shot}-shot_{split}_exp1.txt\") as file:\n",
    "            dict_ann[split] = file.readlines()\n",
    "            # print(dict_ann[split])\n",
    "    \n",
    "        for i_ele, ele in enumerate(dict_ann[split]):\n",
    "            dict_ann[split][i_ele] = [i.strip('\\n') for i in ele.split(' ')]\n",
    "        # print(dict_ann[split])\n",
    "    \n",
    "        # for ele in dict_ann[split]:\n",
    "        #     print((df_label[df_label.index == ele[0]].values.flatten() == np.array(ele[1].split(',')).astype(float)).all(), end=', ')\n",
    "\n",
    "    with open(f\"data_backup/{target}_test_WithLabel.txt\") as file:\n",
    "        dict_ann['test'] = file.readlines()\n",
    "\n",
    "    # print(dict_ann)\n",
    "    \n",
    "    for i_ele, ele in enumerate(dict_ann['test']):\n",
    "        dict_ann['test'][i_ele] = [i.strip('\\n') for i in ele.split(' ')] # [['a.png', '0,1,0,1'], ['b.png', '1,1,0,0']]\n",
    "    \n",
    "    \n",
    "    # --------------------------- CoCoOp ---------------------------\n",
    "    \n",
    "    for i_col, col in enumerate(df_label.columns):\n",
    "        # print(i_col, col)\n",
    "\n",
    "        dict_ann_col = deepcopy(dict_ann)\n",
    "\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            for i_ele, ele in enumerate(dict_ann_col[split]):\n",
    "\n",
    "                if target == \"chest\":\n",
    "                    dict_ann_col[split][i_ele][1] = int(ele[1].split(',')[i_col]) # ['a.png', '0,1,0,1'] -> ['a.png', 0] / ['a.png', 1] / ['a.png', 0] / ['a.png', 0]\n",
    "                elif target == \"colon\":\n",
    "                    dict_ann_col[split][i_ele][1] = dict_ann_col[split][i_ele][0] + ' ' + dict_ann_col[split][i_ele][1]\n",
    "                    dict_ann_col[split][i_ele] = dict_ann_col[split][i_ele][1:]\n",
    "                    ele = dict_ann_col[split][i_ele]\n",
    "                    dict_ann_col[split][i_ele][1] = int(ele[1].split(',')[i_col])\n",
    "                elif target == \"endo\":\n",
    "                    dict_ann_col[split][i_ele] = [dict_ann_col[split][i_ele][0], int(dict_ann_col[split][i_ele][i_col+1])] # ['a.png', '0', '1', '0', '1'] -> ['a.png', 0] / ['a.png', 1] / ['a.png', 0] / ['a.png', 0]\n",
    "                    ele = dict_ann_col[split][i_ele]\n",
    "                \n",
    "                \n",
    "\n",
    "                if dict_ann_col[split][i_ele][1] == 0:\n",
    "                    dict_ann_col[split][i_ele].append(f\"{col}-negative\")\n",
    "                elif dict_ann_col[split][i_ele][1] == 1:\n",
    "                    dict_ann_col[split][i_ele].append(f\"{col}-positive\")\n",
    "        \n",
    "        \n",
    "        with open(f\"./MedFMC/{target}/split_tsai_medfmc_{target}-{shot}shot-{col}.json\", \"w\") as file:\n",
    "            json.dump(dict_ann_col, file)\n",
    "    print(f\"dict_ann_col.keys() = {dict_ann_col.keys()}\")\n",
    "    print(f\"dict_ann_col['train'][0] = {dict_ann_col['train'][0]}\")\n",
    "    \n",
    "    \n",
    "    # --------------------------- VPT ---------------------------\n",
    "    \n",
    "    if target == \"colon\":\n",
    "        for split in [\"train\", \"val\"]:\n",
    "            shutil.copyfile(f\"data_backup/{target}_{shot}-shot_{split}_exp1.txt\", f\"MedFMC/{target}/{target}_{shot}-shot_{split}_exp1.txt\")\n",
    "        shutil.copyfile(f\"data_backup/{target}_train_20.txt\", f\"MedFMC/{target}/{target}_train_20.txt\")\n",
    "        shutil.copyfile(f\"data_backup/{target}_val_20.txt\", f\"MedFMC/{target}/{target}_val_20.txt\")\n",
    "        shutil.copyfile(f\"data_backup/{target}_test_WithLabel.txt\", f\"MedFMC/{target}/{target}_test_WithLabel.txt\")\n",
    "    elif target == \"chest\":\n",
    "        \n",
    "        for split in [\"train\", \"val\"]:\n",
    "            dict_ann_vpt = {'metainfo': {'classes': list(df_label.columns)}, 'data_list': []}\n",
    "            \n",
    "            # data_ann['split']: [['a.png', '0,1,0,1'], ['b.png', '1,1,0,0']]\n",
    "            \n",
    "            for i_ele, ele in enumerate(dict_ann[split]):\n",
    "                dict_ann_vpt['data_list'].append({'img_path': ele[0], 'gt_label': []})\n",
    "                \n",
    "                for j, jj in enumerate(ele[1].split(',')):\n",
    "                    if jj == '1':\n",
    "                        dict_ann_vpt['data_list'][-1]['gt_label'].append(j)\n",
    "            print('<==========')\n",
    "            print(f\"dict_ann[{split}][0:2] = {dict_ann[split][0:2]}\")\n",
    "            print(f\"dict_ann_vpt['metainfo'] = {dict_ann_vpt['metainfo']}\")\n",
    "            print(f\"dict_ann_vpt['data_list'][0:2] = {dict_ann_vpt['data_list'][0:2]}\")\n",
    "            print('==========>')\n",
    "            \n",
    "            with open(f\"MedFMC/{target}/{target}_{shot}-shot_{split}_exp1.pkl\", 'wb') as file:\n",
    "                pickle.dump(dict_ann_vpt, file)\n",
    "        \n",
    "            \n",
    "    elif target == \"endo\":\n",
    "        for split in [\"train\", \"val\"]:\n",
    "            dict_ann_vpt = {'metainfo': {'classes': list(df_label.columns)}, 'data_list': []}\n",
    "            \n",
    "            # data_ann['split']: [['a.png', '0,1,0,1'], ['b.png', '1,1,0,0']]\n",
    "            \n",
    "            for i_ele, ele in enumerate(dict_ann[split]):\n",
    "                dict_ann_vpt['data_list'].append({'img_path': ele[0], 'gt_label': []})\n",
    "                \n",
    "                for j, jj in enumerate(ele[1:]):\n",
    "                    if jj == '1':\n",
    "                        dict_ann_vpt['data_list'][-1]['gt_label'].append(j)\n",
    "            print('<==========')\n",
    "            print(f\"dict_ann[{split}][0:2] = {dict_ann[split][0:2]}\")\n",
    "            print(f\"dict_ann_vpt['metainfo'] = {dict_ann_vpt['metainfo']}\")\n",
    "            print(f\"dict_ann_vpt['data_list'][0:2] = {dict_ann_vpt['data_list'][0:2]}\")\n",
    "            print('==========>')\n",
    "            \n",
    "            with open(f\"MedFMC/{target}/{target}_{shot}-shot_{split}_exp1.pkl\", 'wb') as file:\n",
    "                pickle.dump(dict_ann_vpt, file)\n",
    "    \n",
    "    print('\\n\\n---------------------------------------------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chest 1\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['DX.1.2.392.200046.100.2.1.69131194618.191116084230.1.1.1.png', 0, 'consolidation-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['DX.1.2.392.200046.100.2.1.69131194618.191116084230.1.1.1.png', '1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0'], ['5C2EB54413D4CEC.png', '0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': 'DX.1.2.392.200046.100.2.1.69131194618.191116084230.1.1.1.png', 'gt_label': [0, 4]}, {'img_path': '5C2EB54413D4CEC.png', 'gt_label': [1, 5, 7]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['5E0028D65D00B3A.png', '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0'], ['DX.1.2.840.113564.920101.20191114111648140490.1003000225002.png', '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5E0028D65D00B3A.png', 'gt_label': []}, {'img_path': 'DX.1.2.840.113564.920101.20191114111648140490.1003000225002.png', 'gt_label': []}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "chest 5\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['5B038B1585CD55.png', 0, 'consolidation-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['5B038B1585CD55.png', '1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0'], ['5B52E5261448875.png', '1,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5B038B1585CD55.png', 'gt_label': [0, 13, 17]}, {'img_path': '5B52E5261448875.png', 'gt_label': [0, 2, 3, 4, 5, 6]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['5CF9B326BECC0E.png', '0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0'], ['DX.1.2.0031216000034082612019102910550798627328.png', '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5CF9B326BECC0E.png', 'gt_label': [7]}, {'img_path': 'DX.1.2.0031216000034082612019102910550798627328.png', 'gt_label': []}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "chest 10\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['5B972CB8176C394.png', 0, 'consolidation-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['5B972CB8176C394.png', '1,0,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0'], ['5B948B191330B8C.png', '1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5B972CB8176C394.png', 'gt_label': [0, 2, 3, 4, 6, 7, 8]}, {'img_path': '5B948B191330B8C.png', 'gt_label': [0, 5, 13]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['DX.1.2.392.200046.100.2.1.69131194618.191028115311.1.1.1.png', '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0'], ['DX.1.2.392.200046.100.2.1.69131194618.191114104417.1.1.1.png', '1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': 'DX.1.2.392.200046.100.2.1.69131194618.191028115311.1.1.1.png', 'gt_label': []}, {'img_path': 'DX.1.2.392.200046.100.2.1.69131194618.191114104417.1.1.1.png', 'gt_label': [0, 8]}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "colon 1\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['1903326001_2019-06-11 12_07_06-lv1-3173-23728-2837-3546p0008.png', 0, 'tumor-negative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "colon 5\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['2019-07501-1-1-1_2019-05-29 08_22_25-lv1-9661-18329-4972-6041p0007.png', 0, 'tumor-negative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "colon 10\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['2019-07501-1-1-1_2019-05-29 08_22_25-lv1-9661-18329-4972-6041p0007.png', 0, 'tumor-negative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "endo 1\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['13333_2021.12_0007_57297497.png', 0, 'tumor-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['13333_2021.12_0007_57297497.png', '1', '0', '0', '0'], ['13333_2021.12_0007_57297486.png', '1', '0', '0', '1']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.12_0007_57297497.png', 'gt_label': [0]}, {'img_path': '13333_2021.12_0007_57297486.png', 'gt_label': [0, 3]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['13333_2021.08_0007_51343296.png', '0', '0', '0', '0'], ['13333_2021.04_0003_44800995.png', '0', '1', '0', '0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.08_0007_51343296.png', 'gt_label': []}, {'img_path': '13333_2021.04_0003_44800995.png', 'gt_label': [1]}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "endo 5\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['13333_2021.12_0006_55977222.png', 0, 'tumor-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['13333_2021.12_0006_55977222.png', '1', '1', '0', '0'], ['13333_2021.12_0006_55977215.png', '1', '0', '0', '0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.12_0006_55977222.png', 'gt_label': [0, 1]}, {'img_path': '13333_2021.12_0006_55977215.png', 'gt_label': [0]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['13333_2021.07_0003_49851477.png', '0', '1', '0', '0'], ['13333_2021.08_0007_50953537.png', '0', '0', '1', '0']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.07_0003_49851477.png', 'gt_label': [1]}, {'img_path': '13333_2021.08_0007_50953537.png', 'gt_label': [2]}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n",
      "endo 10\n",
      "dict_ann_col.keys() = dict_keys(['train', 'val', 'test'])\n",
      "dict_ann_col['train'][0] = ['13333_2021.12_0007_57297497.png', 0, 'tumor-negative']\n",
      "<==========\n",
      "dict_ann[train][0:2] = [['13333_2021.12_0007_57297497.png', '1', '0', '0', '0'], ['13333_2021.12_0007_57297486.png', '1', '0', '0', '1']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.12_0007_57297497.png', 'gt_label': [0]}, {'img_path': '13333_2021.12_0007_57297486.png', 'gt_label': [0, 3]}]\n",
      "==========>\n",
      "<==========\n",
      "dict_ann[val][0:2] = [['13333_2021.12_0009_56515792.png', '0', '0', '0', '0'], ['13333_2021.09_0001_51688673.png', '0', '0', '0', '1']]\n",
      "dict_ann_vpt['metainfo'] = {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.12_0009_56515792.png', 'gt_label': []}, {'img_path': '13333_2021.09_0001_51688673.png', 'gt_label': [3]}]\n",
      "==========>\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for target in [\"chest\", \"colon\", \"endo\"]:\n",
    "    for shot in [1, 5, 10]:\n",
    "        print(target, shot)\n",
    "        gen_ann_file(target, shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "<==========\n",
      "data[0:2] = [['5D0984CC1D7C36B.png', '1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0'], ['5E23EE5AF64A05.png', '0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5D0984CC1D7C36B.png', 'gt_label': [0, 2, 4, 11]}, {'img_path': '5E23EE5AF64A05.png', 'gt_label': [1, 14]}]\n",
      "==========>\n",
      "val\n",
      "<==========\n",
      "data[0:2] = [['CR.1.3.12.2.1107.5.3.57.20200.11.201910300851500343.png', '0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0'], ['5CF728A22460CBA.png', '1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': 'CR.1.3.12.2.1107.5.3.57.20200.11.201910300851500343.png', 'gt_label': [3]}, {'img_path': '5CF728A22460CBA.png', 'gt_label': [0, 2, 11]}]\n",
      "==========>\n",
      "test\n",
      "<==========\n",
      "data[0:2] = [['5B91F7409CCCE2.png', '0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0'], ['5DC2824164E8B52.png', '1,0,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '5B91F7409CCCE2.png', 'gt_label': [16]}, {'img_path': '5DC2824164E8B52.png', 'gt_label': [0, 3, 6, 8]}]\n",
      "==========>\n"
     ]
    }
   ],
   "source": [
    "target = \"chest\"\n",
    "\n",
    "for split in [\"train\", \"val\", 'test']:\n",
    "    \n",
    "    if split == \"train\":\n",
    "        file_name = f\"{target}_train_20.txt\"\n",
    "    elif split == \"val\":\n",
    "        file_name = f\"{target}_val_20.txt\"\n",
    "    elif split == \"test\":\n",
    "        file_name = f\"{target}_test_WithLabel.txt\"\n",
    "        \n",
    "    print(split)\n",
    "\n",
    "    dict_ann_vpt = {'metainfo': {'classes': ['pleural_effusion', 'nodule', 'pneumonia', 'cardiomegaly', 'hilar_enlargement', 'fracture_old', 'fibrosis', 'aortic_calcification', 'tortuous_aorta', 'thickened_pleura', 'TB', 'pneumothorax', 'emphysema', 'atelectasis', 'calcification', 'pulmonary_edema', 'increased_lung_markings', 'elevated_diaphragm', 'consolidation']}, 'data_list': []}\n",
    "\n",
    "    with open(f\"data_backup/{file_name}\") as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    for i_ele, ele in enumerate(data):\n",
    "        data[i_ele] = [i.strip('\\n') for i in ele.split(' ')]\n",
    "\n",
    "    for i_ele, ele in enumerate(data):\n",
    "        dict_ann_vpt['data_list'].append({'img_path': ele[0], 'gt_label': []})\n",
    "\n",
    "        for j, jj in enumerate(ele[1].split(',')):\n",
    "            if jj == '1':\n",
    "                dict_ann_vpt['data_list'][-1]['gt_label'].append(j)\n",
    "    print('<==========')\n",
    "    print(f\"data[0:2] = {data[0:2]}\")\n",
    "    # print(f\"dict_ann_vpt['metainfo'] = {dict_ann_vpt['metainfo']}\")\n",
    "    print(f\"dict_ann_vpt['data_list'][0:2] = {dict_ann_vpt['data_list'][0:2]}\")\n",
    "    print('==========>')\n",
    "\n",
    "    with open(f\"MedFMC/{target}/{file_name.replace('txt', 'pkl')}\", 'wb') as file:\n",
    "        pickle.dump(dict_ann_vpt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "<==========\n",
      "data[0:2] = [['13333_2021.09_0003_51743305.png', '0', '0', '0', '0'], ['13333_2021.09_0004_52720383.png', '0', '0', '0', '0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.09_0003_51743305.png', 'gt_label': []}, {'img_path': '13333_2021.09_0004_52720383.png', 'gt_label': []}]\n",
      "==========>\n",
      "val\n",
      "<==========\n",
      "data[0:2] = [['13333_2021.09_0004_52719617.png', '0', '0', '1', '0'], ['13333_2021.09_0004_52720500.png', '0', '0', '1', '0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.09_0004_52719617.png', 'gt_label': [2]}, {'img_path': '13333_2021.09_0004_52720500.png', 'gt_label': [2]}]\n",
      "==========>\n",
      "test\n",
      "<==========\n",
      "data[0:2] = [['13333_2021.11_0003_55200268.png', '0', '0', '0', '0'], ['13333_2021.11_0003_55199880.png', '0', '0', '0', '0']]\n",
      "dict_ann_vpt['data_list'][0:2] = [{'img_path': '13333_2021.11_0003_55200268.png', 'gt_label': []}, {'img_path': '13333_2021.11_0003_55199880.png', 'gt_label': []}]\n",
      "==========>\n"
     ]
    }
   ],
   "source": [
    "target = \"endo\"\n",
    "\n",
    "for split in [\"train\", \"val\", 'test']:\n",
    "    \n",
    "    if split == \"train\":\n",
    "        file_name = f\"{target}_train_20.txt\"\n",
    "    elif split == \"val\":\n",
    "        file_name = f\"{target}_val_20.txt\"\n",
    "    elif split == \"test\":\n",
    "        file_name = f\"{target}_test_WithLabel.txt\"\n",
    "        \n",
    "    print(split)\n",
    "\n",
    "    dict_ann_vpt = {'metainfo': {'classes': ['ulcer', 'erosion', 'polyp', 'tumor']}, 'data_list': []}\n",
    "\n",
    "    with open(f\"data_backup/{file_name}\") as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    for i_ele, ele in enumerate(data):\n",
    "        data[i_ele] = [i.strip('\\n') for i in ele.split(' ')]\n",
    "\n",
    "    for i_ele, ele in enumerate(data):\n",
    "        dict_ann_vpt['data_list'].append({'img_path': ele[0], 'gt_label': []})\n",
    "\n",
    "        for j, jj in enumerate(ele[1:]):\n",
    "            if jj == '1':\n",
    "                dict_ann_vpt['data_list'][-1]['gt_label'].append(j)\n",
    "    print('<==========')\n",
    "    print(f\"data[0:2] = {data[0:2]}\")\n",
    "    # print(f\"dict_ann_vpt['metainfo'] = {dict_ann_vpt['metainfo']}\")\n",
    "    print(f\"dict_ann_vpt['data_list'][0:2] = {dict_ann_vpt['data_list'][0:2]}\")\n",
    "    print('==========>')\n",
    "\n",
    "    with open(f\"MedFMC/{target}/{file_name.replace('txt', 'pkl')}\", 'wb') as file:\n",
    "        pickle.dump(dict_ann_vpt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
